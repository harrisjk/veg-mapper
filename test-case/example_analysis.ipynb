{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>INTRODUCTION</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Paragraph introducing the analysis process, outlining the steps, defining conventions, and providing a framework for the user to understand the notebook. This will also explain the test case data and guide users through the widgets/inputs in the analysis notebook.</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Python/R dual functionality for notebook\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize R cell and load in necessary libraries\n",
    "%%R\n",
    "library(rgdal)\n",
    "library(arm)\n",
    "library(gdalUtils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>EXTRACT</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Description text outlining the objectives of this routine, as well as a general overview of the code cells and what needs to be edited by the user.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">User inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#all GIS data in lat lon WGS84 unless specified\n",
    "#path to comma-delimited file, must have cols 'latitude', 'longitude', 'class'\n",
    "in_points = \"wwf_2018_clipped.csv\"\n",
    "buffer = 1\n",
    "\n",
    "#remote sensing stack in ENVI flat binary format\n",
    "in_stack =  \"indo_stack_nov_2018_clipped\"\n",
    "\n",
    "#path to output comma-delimited file, same as in_points with appended remote sensing values\n",
    "out_points =  \"wwf_2018_clipped_testPred.csv\"\n",
    "\n",
    "#stack information\n",
    "res = 0.000272\n",
    "ulX = 112.9799898400000018\n",
    "ulY = -1.6588637600000000\n",
    "\n",
    "#which bands do you want to use?\n",
    "bands = c(2,3,1,4)\n",
    "stack_names = c(\"vcf\", \"c_rvi\", \"ndvi\", \"l_rvi_mosaic\")\n",
    "\n",
    "nodata = -9999 #NA value present in input bands: NEEDS TO BE A LIST OF NUMBERS IF NOT CONSISTENT ACROSS BANDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Create function to get intensity values from stack, execute extract routine:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "getPixel= function(gdalObject, X, Y, buffer, ulX, ulY, cellSize, bands){\n",
    "    nrow = dim(gdalObject)[1]\n",
    "    ncol = dim(gdalObject)[2]\n",
    "    rowOffset = ((ulY-Y)/cellSize) - buffer\n",
    "    if(rowOffset<0 | (rowOffset+buffer+2) > nrow){\n",
    "        return(NA)\n",
    "    }\n",
    "    colOffset = ((X-ulX)/cellSize) - buffer\n",
    "    if(colOffset<0 | (colOffset+buffer+2) > ncol){\n",
    "        return(NA)\n",
    "    } \n",
    "    windowY = buffer+2\n",
    "    windowX = windowY\n",
    "    pixelValue = getRasterData(gdalObject, band=bands, offset=c(rowOffset, colOffset), region.dim=c(windowY, windowX))\n",
    "    return(pixelValue)\n",
    "}\n",
    "\n",
    "#grab stack\n",
    "gdalObj = new(\"GDALDataset\", in_stack)\n",
    "\n",
    "#append remote sensing information to point table and write to cvs file\n",
    "inData <- read.csv(in_points, header=TRUE)\n",
    "numPoints <- nrow(inData)\n",
    "\n",
    "header <- c(colnames(inData), stack_names)\n",
    "write.table(x=t(header), file=out_points, append=FALSE, col.names=FALSE, row.names=FALSE, sep=\",\")\n",
    "\n",
    "print(\"Extracting values for...\")\n",
    "for(i in 1:numPoints){\n",
    "    allBands <- rep(NA, length(bands))\n",
    "    for (j in 1:length(bands)){\n",
    "        oneBand = getPixel(gdalObj, inData$longitude[i], inData$latitude[i], buffer, ulX, ulY, res, bands[j])\n",
    "        w = which (oneBand == nodata[j])\n",
    "        oneBand[w]<-NA\n",
    "        allBands[j] = mean(oneBand, na.rm=TRUE)\n",
    "        if(i==1) print(stack_names[j])\n",
    "    }\n",
    "  mydata <- data.frame(t(as.vector(allBands)))\n",
    "  colnames(mydata) <- stack_names\n",
    "  newRow = cbind(inData[i,],mydata)\n",
    "  write.table(x=newRow, file=out_points, append=TRUE, col.names=FALSE, row.names=FALSE, sep=\",\") \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>RUN</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Description text outlining the objectives of this routine, as well as a general overview of the code cells and what needs to be edited by the user.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">User inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "data = read.csv(out_points)\n",
    "\n",
    "#treshold for logistic model; \n",
    "#when probability is larger than this threshold, we say that oil palm is present\n",
    "threshold = 0.5\n",
    "\n",
    "#priors (variable order corresponds to order in which bands are read), currently Costa Rica\n",
    "use_prior = TRUE\n",
    "prior_mean = c(0.06491638, -26.63132179, 0.05590800, -29.64091620)\n",
    "prior_scale = c(0.02038204, 7.58200324, 0.01686930, 8.73995422)\n",
    "prior_mean_int = 1.99274801\n",
    "prior_scale_int = 7.22600112\n",
    "\n",
    "#lower and upper bounds for posterior credible intervals\n",
    "lp = 0.025\n",
    "up = 0.975\n",
    "\n",
    "#columns of the predictor variables to be used in this model (taken from pred csv)\n",
    "#column order indicated here is vcf, c_rvi, ndvi, l_rvi_mosaic, matching the priors above\n",
    "index = c(13,14,15,16)\n",
    "#EDIT: find column indices using names of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Create model and execute prediction:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#impute missing values by variable means\n",
    "for (i in which(sapply(data, is.numeric))) {\n",
    "    for (j in which(is.na(data[, i]))) {\n",
    "        data[j, i] <- mean(data[data[, \"my_class\"] == data[j, \"my_class\"], i],  na.rm = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "#true_label: 1 for oil_palm and 0 for non oil_palm\n",
    "true_label = 1*(data$my_class == 'oil_palm')\n",
    "\n",
    "#transform interested variables into a matrix which would be used\n",
    "x = as.matrix(data[, index])\n",
    "all_names = names(data)\n",
    "stack_names = all_names[index]\n",
    "colnames(x) = stack_names\n",
    "\n",
    "#build model by incorporating those variables\n",
    "formula = as.formula(paste(\"true_label ~ \", paste(stack_names, collapse=\"+\"),sep = \"\"))\n",
    "use_data = as.data.frame(cbind(x, true_label))\n",
    "\n",
    "#to specify prior\n",
    "#if noninformative prior, use prior.mean=apply(x, 2, mean), prior.scale=Inf, prior.df=Inf\n",
    "#if having a prior, set prior.mean=c(....), prior.scale=c(.....)\n",
    "#length of prior mean and prior scale should be equal to the number of predictors\n",
    "if(! use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), prior.mean=apply(x, 2, mean), prior.scale=Inf, scale=FALSE)\n",
    "}\n",
    "if(use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), \n",
    "                    prior.mean=prior_mean,\n",
    "                    prior.scale=prior_scale,\n",
    "                    prior.mean.for.intercept=prior_mean_int,\n",
    "                    prior.scale.for.intercept=prior_scale_int,\n",
    "            scale = FALSE)\n",
    "}\n",
    "\n",
    "#oil_palm prediction\n",
    "class_prediction = 1*(model$fitted.values >= threshold) #if the fitted value is above the threshold, value is changed to binary 1\n",
    "print(class_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Construct confusion matrix, calculate prediction accuracy, posterior CI, print result:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#used instead of na.remove to get rid of NA values in 2018 validation dataset\n",
    "true_label = true_label[!is.na(true_label)]\n",
    "\n",
    "#generate confusion matrix\n",
    "bayesian_conf_matrix = matrix(0,2,2)\n",
    "bayesian_conf_matrix[1,1] = sum(class_prediction + true_label == 0)\n",
    "bayesian_conf_matrix[2,2] = sum(class_prediction + true_label == 2)\n",
    "bayesian_conf_matrix[1,2] = sum((class_prediction == 0) & (true_label == 1))\n",
    "bayesian_conf_matrix[2,1] = sum((class_prediction == 1) & (true_label == 0))\n",
    "rownames(bayesian_conf_matrix) = c(\"Predicted non-oil-palm\", \"Predicted oil-palm\")\n",
    "colnames(bayesian_conf_matrix) = c(\"Actual non-oil-palm\", \"Actual oil-palm\")\n",
    "print(bayesian_conf_matrix)\n",
    "\n",
    "#overall accuracy of model\n",
    "accu_bayes = sum(class_prediction == true_label) / nrow(data)\n",
    "print(\"Overall accuracy:\")\n",
    "print(accu_bayes)\n",
    "\n",
    "#EDIT: push values to Python and use numpy/matplotlib to display matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Calculate/build posteriors for subsequent runs, print result:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# approach posterior distributions of coefficients\n",
    "# specify number of draws \n",
    "num_draw = 2000\n",
    "post_dist = sim(model, n.sims=num_draw)\n",
    "coef_matrix = coef(post_dist)\n",
    "\n",
    "# calculate posterior credible intervals for coefficients\n",
    "posterior_ci_coef = matrix(NA, ncol(x)+1, 2)\n",
    "for (i in 1:(ncol(x)+1)){\n",
    "    posterior_ci_coef[i, ] = unname(quantile(coef_matrix[, i], probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# calculate posterior credible intervals for every data point\n",
    "posterior_ci_data = matrix(NA, nrow(x), 2)\n",
    "for(i in 1:nrow(x)){\n",
    "    temp = as.numeric()\n",
    "    for(j in 1:num_draw){\n",
    "        temp[j] = 1 / (1 + exp(-coef_matrix[j, 1] - sum(coef_matrix[j, 2:(length(index)+1)] * x[i, ])))\n",
    "    }\n",
    "    posterior_ci_data[i, ] = unname(quantile(temp, probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# build posterior objects for next run\n",
    "posterior_mean = model$coefficients\n",
    "posterior_scale = apply(coef(post_dist), 2, sd)\n",
    "\n",
    "#print the posteriors\n",
    "posterior_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>APPLY</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Description text outlining the objectives of this routine, as well as a general overview of the code cells and what needs to be edited by the user.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">User inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#your input stack\n",
    "inStack = \"indo_stack_nov_2018_clipped\"\n",
    "\n",
    "#names for all the bands in your stack. \n",
    "bandNames = c('ndvi', 'vcf', 'cband_rvi', 'lrvi', 'alpha', 'lambda', 'entropy', 'anisotropy', 'hh', 'mask', 'lband_rvi')\n",
    "\n",
    "#dummy corresponds to one band from the original stack, it can be generated with gdal_translate \n",
    "    #this band is used to save your output prediction map \n",
    "# inDummy = \"/Users/hknapp/Documents/PalmMonday/src_data/dummy_indo_RStudio_TEST\" #creates empty raster at the size and resolution of in_data\n",
    "inDummy = \"dummy_indo_nov_2018_clipped\" #Docker testing\n",
    "\n",
    "#name of the output map\n",
    "outPred = \"op3_indo_nov_2018_clipped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Model parameters:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#which bands are used in the model?\n",
    "    #may be a subset of the stack, names must be consistent with bandNames defined above\n",
    "fitBands = c(\"vcf\", \"cband_rvi\", \"ndvi\", \"lband_rvi\")\n",
    "\n",
    "#model parameters from your site, obtained with run_OP3-G20.R\n",
    "    #the coefficients match the variable names above\n",
    "#EDIT: Fix this and connect variables from previous step\n",
    "intercept =  7.77338858\n",
    "posteriors = c(0.06768467, -43.16767103, 0.03948285, -9.89497112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Generate dummy:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#generate dummy for Docker\n",
    "    #only use env variables if creation fails (will normally return NULL but still create object)\n",
    "# Sys.setenv(PROJ_LIB=\"/usr/bin/proj/\")\n",
    "# Sys.getenv(\"PROJ_LIB\")\n",
    "gdal_translate(src_dataset=inStack, dst_dataset=inDummy, of=\"ENVI\", b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Apply model to stack, execute predictive analysis:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#determine bands to use\n",
    "modelBands = rep(NA, length(fitBands))\n",
    "for(i in 1:length(modelBands)){\n",
    "    w = which(bandNames == fitBands[i])\n",
    "    modelBands[i] = w\n",
    "}\n",
    "\n",
    "#create GIS objects\n",
    "gdalObjStack = new(\"GDALDataset\", inStack)\n",
    "gdalObjDummy = new(\"GDALDataset\", inDummy)\n",
    "rasterWidth = ncol(gdalObjStack)\n",
    "rasterRows = nrow(gdalObjStack)\n",
    "\n",
    "#calculate prediction for each pixel and save\n",
    "print(\"Checking a few values...\")\n",
    "for(i in 1:rasterRows){\n",
    "    oneRasterLine = getRasterData(gdalObjStack, offset=c(i-1,0), region.dim=c(1, rasterWidth))\n",
    "    hhBand = which(bandNames == \"alos2_hh\")\n",
    "    pred = rep(-9999, rasterWidth)\n",
    "    for(j in 1:rasterWidth){\n",
    "        #hh = (20*log10(oneRasterLine[j, 1, hhBand])) -83\n",
    "        hh = oneRasterLine[j, 1, hhBand] #gets hh value at each of the pixels\n",
    "        #open water mask\n",
    "        #if(is.na(hh) | hh < -20){ \n",
    "        #pred[j] = 0\n",
    "        #} \n",
    "        #else{\n",
    "            #select bands\n",
    "            selectBands = oneRasterLine[j, 1, modelBands]\n",
    "            z = (intercept + sum(posteriors * selectBands))\n",
    "            pred[j] = exp(z)/(1+ exp(z))\n",
    "            #z = (intercept + sum(posteriors * scaledBands))\n",
    "            #pred[j] = exp(z)/(1+ exp(z))\n",
    "            if ((i/100 == i%/%100) & j == 1000) print(z) #reality check on the model fits\n",
    "        #}\n",
    "    }\n",
    "    #write one row to file\n",
    "    putRasterData(gdalObjDummy, pred, offset=c(i-1, 0)) #place predicted line in raster into dummy\n",
    "}\n",
    "saveDataset(gdalObjDummy, outPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Convert to GeoTiff:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "gdal_translate(src_dataset=outPred, dst_dataset=\"predSurface.tif\", of=\"GTiff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
